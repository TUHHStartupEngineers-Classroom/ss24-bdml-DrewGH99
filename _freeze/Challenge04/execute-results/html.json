{
  "hash": "9001f0509fd64cc90a6486187c53698d",
  "result": {
    "markdown": "---\ntitle: \"Automated Machine Learning with H2O(II)\"\nsubtitle: \"Business Decisions with Machine Learning\"\nauthor: \"Drew Gilmore\"\n---\n\n::: {.cell hash='Challenge04_cache/html/unnamed-chunk-1_1c080bd019ccc07ecaaef2c404ce7a42'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rsample)\nlibrary(recipes)\nlibrary(h2o)\n\n# 1) Load the training & test dataset\n\nbackorders_tbl <- read_csv(\"Challenge 4/product_backorders.csv\")\n\n# 2) Specifiy the response and predictor variables\n\nprocessed_tbl <- backorders_tbl %>%\n  mutate_if(is.character, as.factor) \n\n# Split Data\nset.seed(seed = 1114)\nsplit_obj <- rsample::initial_split(processed_tbl, prop = 0.85)\n\n# Assign training and test data\ntrain_readable_tbl <- training(split_obj)\ntest_readable_tbl  <- testing(split_obj)\n\nrecipe_obj <- recipe(went_on_backorder ~ ., data = train_readable_tbl) %>%\n  step_zv(all_predictors()) %>%\n  prep()\n\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)\n\n# 3) Run AutoML specifying the stopping criterion\n\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         8 hours 32 minutes \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    6 months and 4 days \n    H2O cluster name:           H2O_started_from_R_Drew_Gilmore_jzg642 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   1.61 GB \n    H2O cluster total cores:    4 \n    H2O cluster allowed cores:  4 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.4.0 (2024-04-24 ucrt) \n```\n:::\n\n```{.r .cell-code}\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1385)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# Set the target and predictors\ny <- \"went_on_backorder\"\nx <- setdiff(names(train_h2o), y)\n\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 30,\n  nfolds            = 5 \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |============                                                          |  17%\n23:30:54.666: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n23:30:54.669: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# 4) View the leaderboard\n\nautoml_models_h2o@leaderboard\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                 model_id       auc   logloss\n1 StackedEnsemble_BestOfFamily_1_AutoML_6_20240624_233054 0.9461077 0.1842937\n2                          GBM_1_AutoML_6_20240624_233054 0.9460588 0.1880829\n3 StackedEnsemble_BestOfFamily_2_AutoML_6_20240624_233054 0.9457692 0.1848656\n4                          GBM_3_AutoML_6_20240624_233054 0.9070224 0.3062381\n5                          DRF_1_AutoML_6_20240624_233054 0.8758876 0.3153469\n6                          GBM_4_AutoML_6_20240624_233054 0.8754304 0.3070348\n      aucpr mean_per_class_error      rmse        mse\n1 0.7437070            0.1513322 0.2352370 0.05533646\n2 0.7437078            0.1513322 0.2376794 0.05649147\n3 0.7403534            0.1495953 0.2354740 0.05544803\n4 0.5767642            0.1780712 0.3024376 0.09146849\n5 0.5509419            0.2177632 0.2810417 0.07898443\n6 0.5539201            0.1789795 0.3019374 0.09116616\n\n[8 rows x 7 columns] \n```\n:::\n\n```{.r .cell-code}\nextract_h2o_model_name_by_position <- function(h2o_leaderboard, n = 1, verbose = T) {\n  \n  model_name <- h2o_leaderboard %>%\n    as.tibble() %>%\n    slice(n) %>%\n    pull(model_id)\n  \n  if (verbose) message(model_name)\n  \n  return(model_name)\n  \n}\n\nautoml_models_h2o@leaderboard %>% \n  extract_h2o_model_name_by_position(1) %>% \n  h2o.getModel()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel Details:\n==============\n\nH2OBinomialModel: stackedensemble\nModel ID:  StackedEnsemble_BestOfFamily_1_AutoML_6_20240624_233054 \nModel Summary for Stacked Ensemble: \n                                   key            value\n1                    Stacking strategy cross_validation\n2 Number of base models (used / total)              1/2\n3     # GBM base models (used / total)              1/1\n4     # GLM base models (used / total)              0/1\n5                Metalearner algorithm              GLM\n6   Metalearner fold assignment scheme           Random\n7                   Metalearner nfolds                5\n8              Metalearner fold_column               NA\n9   Custom metalearner hyperparameters             None\n\n\nH2OBinomialMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.03980472\nRMSE:  0.1995112\nLogLoss:  0.1360083\nMean Per-Class Error:  0.1194987\nAUC:  0.9718998\nAUCPR:  0.8372515\nGini:  0.9437996\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n         No  Yes    Error       Rate\nNo     8479  328 0.037243  =328/8807\nYes     230  910 0.201754  =230/1140\nTotals 8709 1238 0.056097  =558/9947\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold       value idx\n1                       max f1  0.370846    0.765349 186\n2                       max f2  0.186427    0.820919 250\n3                 max f0point5  0.542126    0.793369 132\n4                 max accuracy  0.474180    0.948025 154\n5                max precision  0.979899    1.000000   0\n6                   max recall  0.005868    1.000000 383\n7              max specificity  0.979899    1.000000   0\n8             max absolute_mcc  0.462714    0.736284 157\n9   max min_per_class_accuracy  0.174979    0.912281 254\n10 max mean_per_class_accuracy  0.186427    0.913850 250\n11                     max tns  0.979899 8807.000000   0\n12                     max fns  0.979899 1137.000000   0\n13                     max fps  0.000567 8807.000000 399\n14                     max tps  0.005868 1140.000000 383\n15                     max tnr  0.979899    1.000000   0\n16                     max fnr  0.979899    0.997368   0\n17                     max fpr  0.000567    1.000000 399\n18                     max tpr  0.005868    1.000000 383\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.05699688\nRMSE:  0.2387402\nLogLoss:  0.19193\nMean Per-Class Error:  0.1447631\nAUC:  0.9394651\nAUCPR:  0.7231171\nGini:  0.8789302\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n         No Yes    Error       Rate\nNo     1937 148 0.070983  =148/2085\nYes      66 236 0.218543    =66/302\nTotals 2003 384 0.089652  =214/2387\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold       value idx\n1                       max f1  0.235350    0.688047 222\n2                       max f2  0.126084    0.769231 271\n3                 max f0point5  0.523812    0.720268 128\n4                 max accuracy  0.523812    0.924173 128\n5                max precision  0.857546    0.904762  25\n6                   max recall  0.004454    1.000000 386\n7              max specificity  0.962428    0.999520   0\n8             max absolute_mcc  0.232775    0.642938 223\n9   max min_per_class_accuracy  0.117448    0.877483 276\n10 max mean_per_class_accuracy  0.098896    0.880113 284\n11                     max tns  0.962428 2084.000000   0\n12                     max fns  0.962428  302.000000   0\n13                     max fps  0.000510 2085.000000 399\n14                     max tps  0.004454  302.000000 386\n15                     max tnr  0.962428    0.999520   0\n16                     max fnr  0.962428    1.000000   0\n17                     max fpr  0.000510    1.000000 399\n18                     max tpr  0.004454    1.000000 386\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.05425121\nRMSE:  0.2329189\nLogLoss:  0.17988\nMean Per-Class Error:  0.1729684\nAUC:  0.9436691\nAUCPR:  0.7062248\nGini:  0.8873382\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n          No  Yes    Error         Rate\nNo     11597  612 0.050127   =612/12209\nYes      473 1126 0.295810    =473/1599\nTotals 12070 1738 0.078578  =1085/13808\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold        value idx\n1                       max f1  0.361929     0.674858 191\n2                       max f2  0.101590     0.752962 301\n3                 max f0point5  0.568730     0.690663 122\n4                 max accuracy  0.491365     0.925913 148\n5                max precision  0.985086     1.000000   0\n6                   max recall  0.001473     1.000000 396\n7              max specificity  0.985086     1.000000   0\n8             max absolute_mcc  0.418889     0.632649 172\n9   max min_per_class_accuracy  0.126088     0.872471 287\n10 max mean_per_class_accuracy  0.101590     0.880322 301\n11                     max tns  0.985086 12209.000000   0\n12                     max fns  0.985086  1598.000000   0\n13                     max fps  0.000332 12209.000000 399\n14                     max tps  0.001473  1599.000000 396\n15                     max tnr  0.985086     1.000000   0\n16                     max fnr  0.985086     0.999375   0\n17                     max fpr  0.000332     1.000000 399\n18                     max tpr  0.001473     1.000000 396\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nCross-Validation Metrics Summary: \n                mean        sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid\naccuracy    0.925544  0.004586   0.930416   0.929035   0.926407   0.922497\nauc         0.943698  0.003699   0.948186   0.946199   0.942446   0.938560\nerr         0.074456  0.004586   0.069584   0.070965   0.073593   0.077503\nerr_count 205.800000 17.152260 194.000000 186.000000 204.000000 216.000000\nf0point5    0.678563  0.018021   0.695067   0.681029   0.694268   0.670520\n          cv_5_valid\naccuracy    0.919366\nauc         0.943100\nerr         0.080634\nerr_count 229.000000\nf0point5    0.651931\n\n---\n                        mean        sd cv_1_valid cv_2_valid  cv_3_valid\nprecision           0.677374  0.026046   0.697749   0.682927    0.703226\nr2                  0.470248  0.011549   0.481763   0.473854    0.478286\nrecall              0.685129  0.018774   0.684543   0.673539    0.660606\nresidual_deviance 993.331540 58.421497 961.267940 909.583100 1008.085400\nrmse                0.232826  0.004611   0.228527   0.227882    0.233912\nspecificity         0.956998  0.006683   0.961959   0.960944    0.962326\n                   cv_4_valid  cv_5_valid\nprecision            0.662857    0.640110\nr2                   0.453419    0.463918\nrecall               0.703030    0.703928\nresidual_deviance 1055.826800 1031.894300\nrmse                 0.238864    0.234943\nspecificity          0.951974    0.947788\n```\n:::\n\n```{.r .cell-code}\n# 5 & 6) Save and predicting using Leader Model\n\nh2o.getModel(\"StackedEnsemble_BestOfFamily_2_AutoML_3_20240624_225721\") %>% \n  h2o.saveModel(path = \"h20_models/\", force = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"C:\\\\Users\\\\Drew Gilmore\\\\Documents\\\\GitHub\\\\ss24-bdml-DrewGH99\\\\h20_models\\\\StackedEnsemble_BestOfFamily_2_AutoML_3_20240624_225721\"\n```\n:::\n\n```{.r .cell-code}\nstacked_ensemble_h2o <- h2o.loadModel(\"h20_models/StackedEnsemble_BestOfFamily_2_AutoML_3_20240624_225721\")\n\npredictions <- h2o.predict(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntypeof(predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"environment\"\n```\n:::\n\n```{.r .cell-code}\npredictions_tbl <- predictions %>% as_tibble()\n\npredictions_tbl %>% head(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 Ã— 3\n   predict    No   Yes\n   <fct>   <dbl> <dbl>\n 1 Yes     0.102 0.898\n 2 Yes     0.114 0.886\n 3 Yes     0.190 0.810\n 4 Yes     0.137 0.863\n 5 Yes     0.320 0.680\n 6 Yes     0.149 0.851\n 7 Yes     0.245 0.755\n 8 Yes     0.605 0.395\n 9 Yes     0.411 0.589\n10 No      0.757 0.243\n```\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}