{
  "hash": "6e33d998e9cca0bc01e7cc0ff85d34ee",
  "result": {
    "markdown": "---\ntitle: \"Explainable Black-Box Models with LIME\"\nsubtitle: \"Business Decisions with Machine Learning\"\nauthor: \"Drew Gilmore\"\n---\n\n\n# Script\n\n::: {.cell hash='Challenge06_cache/html/unnamed-chunk-1_0a16e5c3afdd6230197dcfe9187e836f'}\n\n```{.r .cell-code}\nlibrary(h2o)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n----------------------------------------------------------------------\n\nYour next step is to start H2O:\n    > h2o.init()\n\nFor H2O package documentation, ask for help:\n    > ??h2o\n\nAfter starting H2O, you can use the Web UI at http://localhost:54321\nFor more information visit https://docs.h2o.ai\n\n----------------------------------------------------------------------\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'h2o'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    cor, sd, var\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n    colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n    log10, log1p, log2, round, signif, trunc\n```\n:::\n\n```{.r .cell-code}\nlibrary(recipes)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: dplyr\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'recipes'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:stats':\n\n    step\n```\n:::\n\n```{.r .cell-code}\nlibrary(readxl)\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.5.1     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ lubridate::day()   masks h2o::day()\n✖ dplyr::filter()    masks stats::filter()\n✖ stringr::fixed()   masks recipes::fixed()\n✖ lubridate::hour()  masks h2o::hour()\n✖ dplyr::lag()       masks stats::lag()\n✖ lubridate::month() masks h2o::month()\n✖ lubridate::week()  masks h2o::week()\n✖ lubridate::year()  masks h2o::year()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidyquant)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: PerformanceAnalytics\nLoading required package: xts\nLoading required package: zoo\n\nAttaching package: 'zoo'\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n######################### Warning from 'xts' package ##########################\n#                                                                             #\n# The dplyr lag() function breaks how base R's lag() function is supposed to  #\n# work, which breaks lag(my_xts). Calls to lag(my_xts) that you type or       #\n# source() into this session won't work correctly.                            #\n#                                                                             #\n# Use stats::lag() to make sure you're not using dplyr::lag(), or you can add #\n# conflictRules('dplyr', exclude = 'lag') to your .Rprofile to stop           #\n# dplyr from breaking base R's lag() function.                                #\n#                                                                             #\n# Code in packages is not affected. It's protected by R's namespace mechanism #\n# Set `options(xts.warn_dplyr_breaks_lag = FALSE)` to suppress this warning.  #\n#                                                                             #\n###############################################################################\n\nAttaching package: 'xts'\n\nThe following objects are masked from 'package:dplyr':\n\n    first, last\n\n\nAttaching package: 'PerformanceAnalytics'\n\nThe following object is masked from 'package:graphics':\n\n    legend\n\nLoading required package: quantmod\nLoading required package: TTR\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n```\n:::\n\n```{.r .cell-code}\nlibrary(lime)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'lime' was built under R version 4.4.1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'lime'\n\nThe following object is masked from 'package:dplyr':\n\n    explain\n```\n:::\n\n```{.r .cell-code}\n# h2o modeling ----\nemployee_attrition_tbl <- read_csv(\"Challenge 4/datasets-1067-1925-WA_Fn-UseC_-HR-Employee-Attrition.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 1470 Columns: 35\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (9): Attrition, BusinessTravel, Department, EducationField, Gender, Job...\ndbl (26): Age, DailyRate, DistanceFromHome, Education, EmployeeCount, Employ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\ndefinitions_raw_tbl    <- read_excel(\"Challenge 4/data_definitions.xlsx\", sheet = 1, col_names = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n• `` -> `...1`\n• `` -> `...2`\n```\n:::\n\n```{.r .cell-code}\n# Processing Pipeline\nsource(\"Challenge 4/data_processing_pipeline.R\")\n\nemployee_attrition_readable_tbl <- process_hr_data_readable(employee_attrition_tbl, definitions_raw_tbl)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(Education)`\nJoining with `by = join_by(EnvironmentSatisfaction)`\nJoining with `by = join_by(JobInvolvement)`\nJoining with `by = join_by(JobSatisfaction)`\nJoining with `by = join_by(PerformanceRating)`\nJoining with `by = join_by(RelationshipSatisfaction)`\nJoining with `by = join_by(WorkLifeBalance)`\n```\n:::\n\n```{.r .cell-code}\nlibrary(rsample)\n# Split into test and train\nset.seed(seed = 1113)\nsplit_obj <- rsample::initial_split(employee_attrition_readable_tbl, prop = 0.85)\n\n# Assign training and test data\ntrain_readable_tbl <- training(split_obj)\ntest_readable_tbl  <- testing(split_obj)\n\n# ML Preprocessing Recipe \nrecipe_obj <- recipe(Attrition ~ ., data = train_readable_tbl) %>%\n  step_zv(all_predictors()) %>%\n  step_mutate_at(c(\"JobLevel\", \"StockOptionLevel\"), fn = as.factor) %>% \n  prep()\n\nrecipe_obj\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n── Inputs \nNumber of variables by role\noutcome:    1\npredictor: 34\n\n── Training information \nTraining data contained 1249 data points and no incomplete rows.\n\n── Operations \n• Zero variance filter removed: EmployeeCount and Over18, ... | Trained\n• Variable mutation for: JobLevel and StockOptionLevel | Trained\n```\n:::\n\n```{.r .cell-code}\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)\n\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         15 minutes 55 seconds \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    6 months and 5 days \n    H2O cluster name:           H2O_started_from_R_Drew_Gilmore_drs368 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   1.66 GB \n    H2O cluster total cores:    4 \n    H2O cluster allowed cores:  4 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.4.0 (2024-04-24 ucrt) \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in h2o.clusterInfo(): \nYour H2O cluster version is (6 months and 5 days) old. There may be a newer version available.\nPlease download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n```\n:::\n\n```{.r .cell-code}\n## Split data ----\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n## Set the target and predictors ----\ny <- \"Attrition\"\nx <- setdiff(names(train_h2o), y)\n\n## train data\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 30,\n  nfolds            = 5 \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |===                                                                   |   5%\n14:27:02.354: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n14:27:02.356: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=================================================                     |  71%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\nautoml_leader_id <- automl_models_h2o@leader@model_id\npath <- (\"h20_models/Challenge 6/\")\nautoml_leader_path <- paste0(path, automl_leader_id)\n\nh2o.getModel(automl_models_h2o@leader@model_id) %>%\n  h2o.saveModel(path = \"h20_models/Challenge 6/\", force = T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"C:\\\\Users\\\\Drew Gilmore\\\\Documents\\\\GitHub\\\\ss24-bdml-DrewGH99\\\\h20_models\\\\Challenge 6\\\\StackedEnsemble_BestOfFamily_2_AutoML_3_20240626_142702\"\n```\n:::\n\n```{.r .cell-code}\nautoml_leader <- h2o.loadModel(automl_leader_path)\n\npredictions_tbl <- automl_leader %>% \n  h2o.predict(newdata = as.h2o(test_tbl)) %>%\n  as.tibble() %>%\n  bind_cols(\n    test_tbl %>%\n      select(Attrition, EmployeeNumber)\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `as.tibble()` was deprecated in tibble 2.0.0.\nℹ Please use `as_tibble()` instead.\nℹ The signature and semantics have changed, see `?as_tibble`.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n# Create Explainer ----\n\nexplainer <- train_tbl %>%\n  select(-Attrition) %>%\n  lime(\n    model           = automl_leader,\n    bin_continuous  = TRUE,\n    n_bins          = 4,\n    quantile_bins   = TRUE\n  )\n\n# Create Explanation ----\n\nexplanation <- test_tbl %>%\n  slice(1) %>%\n  select(-Attrition) %>%\n  lime::explain(\n    \n    # Pass our explainer object\n    explainer = explainer,\n    # Because it is a binary classification model: 1\n    n_labels   = 1,\n    # number of features to be returned\n    n_features = 8,\n    # number of localized linear models\n    n_permutations = 5000,\n    # Let's start with 1\n    kernel_width   = 1\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\n## Multiple Explanations ----\n\nexplanation <- test_tbl %>%\n  slice(1:20) %>%\n  select(-Attrition) %>%\n  lime::explain(\n    explainer = explainer,\n    n_labels   = 1,\n    n_features = 8,\n    n_permutations = 5000,\n    kernel_width   = 0.5\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n:::\n\n\n# Challenge Part 1\n\n::: {.cell hash='Challenge06_cache/html/plot_79a169e1308c6905fedea64e6c2ae2bb'}\n\n```{.r .cell-code}\n# Challenge Part 1 ----\n\ncase_1 <- explanation %>%\n  filter(case == 1)\n\n#case_1 %>%\n  #plot_features()\n\n\nlabel_both_upper <- function(labels, multi_line = TRUE, sep = ': ') {\n  #names(labels) <- toTitleCase(names(labels))\n  label_both(labels, multi_line, sep)\n}\n  \n\ncase_1$type <- factor(ifelse(sign(case_1$feature_weight) == 1, 'Supports', 'Contradicts'))\ndescription <- paste0(case_1$case, '_', case_1[['label']])\ndesc_width <- max(nchar(description)) + 1\ndescription <- paste0(format(description, width = desc_width), case_1$feature_desc)\ncase_1$description <- factor(description, levels = description[order(abs(case_1$feature_weight))])\ncase_1$case <- factor(case_1$case, unique(case_1$case))\ncase_1$`case_1 fit` <- format(case_1$model_r2, digits = 2)\n\n\ncase_1$probability <- format(case_1$label_prob, digits = 2)\ncase_1$label <- factor(case_1$label, unique(case_1$label[order(case_1$label_prob, decreasing = TRUE)]))\np <- ggplot(case_1) +\n  facet_wrap(~ case + label + probability + `case_1 fit`, scales = 'free_y', ncol = 2, labeller = label_both_upper)\n\np +\n  geom_col(aes_(~description, ~feature_weight, fill = ~type)) +\n  coord_flip() +\n  scale_fill_manual(values = c('lightcoral', 'green3'), drop = FALSE) +\n  scale_x_discrete(labels = function(lab) substr(lab, desc_width + 1, nchar(lab))) +\n  labs(y = 'Weight', x = 'Feature', fill = '') +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](Challenge06_files/figure-html/plot-1.png){width=672}\n:::\n:::\n\n\n# Challenge Part 2\n\n::: {.cell hash='Challenge06_cache/html/plot2_c062c8fc60ef8a4fc2ba7fa0d4775d1e'}\n\n```{.r .cell-code}\n# Challenge Part 2 ----\n\nexplanation$feature_desc <- factor(\n  explanation$feature_desc,\n  levels = rev(unique(explanation$feature_desc[order(explanation$feature, explanation$feature_value)]))\n)\np <- ggplot(explanation, aes_(~case, ~feature_desc)) +\n  geom_tile(aes_(fill = ~feature_weight)) +\n  scale_x_discrete('Case', expand = c(0, 0)) +\n  scale_y_discrete('Feature', expand = c(0, 0)) +\n  scale_fill_gradient2('Feature\\nweight', low = 'lightcoral', mid = '#f7f7f7', high = 'green3') +\n  theme_minimal() +\n  theme(panel.border = element_rect(fill = NA, colour = 'grey60', size = 1),\n        panel.grid = element_blank(),\n        legend.position = 'right',\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))\np\n```\n\n::: {.cell-output-display}\n![](Challenge06_files/figure-html/plot2-1.png){width=672}\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}